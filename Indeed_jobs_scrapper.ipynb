{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "#from random import random\n",
    "from time import sleep\n",
    "#from email.message import EmailMessage\n",
    "#from collections import namedtuple\n",
    "#import smtplib\n",
    "import csv\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same thing for Data scientist, analyst, engineer, software engineer, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for all URLs\n",
    "indeed_url = 'https://www.indeed.com'\n",
    "job_search_url = 'https://www.indeed.com/jobs?q={}&l={}'\n",
    "job_search_id = 'Data analyst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(title,location):\n",
    "    url = job_search_url.format(title,location)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_url(job_search_id,'United States')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "job_cards = soup.find_all('div','jobsearch-SerpJobCard')\n",
    "len(job_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = job_cards[0]\n",
    "atag = card.h2.a\n",
    "title = atag.get('title') #get method is prefered as it handles key not found error\n",
    "\n",
    "job_desc = indeed_url + atag.get('href')\n",
    "company_name = card.find('span', 'company').text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/company/Enlightened/jobs/Data-Analyst-53330da1480565e8?fccid=0d4958dd09ddbb85&vjs=3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = card.find('div','recJobLoc').get('data-rc-loc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' DC'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sate = location.split(',')[1]\n",
    "sate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "posted_date = card.find('span','date').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().strftime('%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    salary = card.find('span','salaryText').text.strip()\n",
    "except AttributeError:\n",
    "    salary = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    job_rating = card.find('span','ratingsContent').text.strip()\n",
    "except AttributeError:\n",
    "    job_rating = ''\n",
    "job_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get job details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all the skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_details = requests.get(job_desc)\n",
    "job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_soup = BeautifulSoup(job_details.text, 'html.parser')\n",
    "\n",
    "job_desc = detail_soup.find('div','jobsearch-jobDescriptionText').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get job data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_card(card):\n",
    "    title = card.h2.a.get('title') #get method is prefered as it handles key not found error\n",
    "   \n",
    "   \n",
    "    company_name = card.find('span', 'company').text.strip()\n",
    "    location = card.find('div','recJobLoc').get('data-rc-loc')\n",
    "   \n",
    "    if(',' in location):\n",
    "        state = location.split(',')[1].strip()\n",
    "    else:\n",
    "        state = location\n",
    "    \n",
    "    try:\n",
    "        salary = card.find('span','salaryText').text.strip()\n",
    "    except AttributeError:\n",
    "        salary = ''\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        job_rating = card.find('span','ratingsContent').text.strip()\n",
    "    except AttributeError:\n",
    "        job_rating = ''\n",
    "        \n",
    "    posted_date = card.find('span','date').text\n",
    "    today = date.today().strftime('%m/%d/%y')\n",
    "    \n",
    "    job_desc_url = indeed_url + card.h2.a.get('href')\n",
    "    job_desc = get_job_desc(job_desc_url)\n",
    "    \n",
    "    card_data = (job_search_id,title, company_name, location, state, salary, job_rating, posted_date, today,job_desc_url,job_desc)\n",
    "    return card_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listing_data = []\n",
    "\n",
    "for card in job_cards:\n",
    "    job_listing_data.append(get_data_from_card(card))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Data analyst',\n",
       " 'Data Analyst',\n",
       " 'BlueLabs Analytics',\n",
       " 'Washington, DC',\n",
       " 'DC',\n",
       " '$67,000 a year',\n",
       " '',\n",
       " '30+ days ago',\n",
       " '03/29/21',\n",
       " 'https://www.indeed.com/rc/clk?jk=3cb092c49648dfe3&fccid=53b041cb411b8ed4&vjs=3',\n",
       " \"The Company\\nBlueLabs is a leading provider of analytics services and technology for government, business, and campaigns. Founded in 2013 by senior members of the Obama for America re-election campaign team, we help our clients optimize their engagements with individual customers, supporters and stakeholders to achieve their goals.\\nToday, our team counts over 40 data scientists, engineers, and strategists from diverse backgrounds who share a passion for using data to solve the world’s greatest social and analytical challenges. We’ve served more than 400 organizations ranging from political campaigns to advocacy groups, unions, government agencies, and international groups, as well as companies in the automotive, travel, consumer packaged goods, entertainment, healthcare, media, telecom, and other industries. Along the way, we’ve developed some of the most innovative tools available in analytics, media optimization, reporting, and influencer outreach.\\nData Analyst\\nData Analysts are instrumental members of BlueLabs Data Science and engagement teams. They gain exposure to all parts of our process, from collecting and organizing data, to analyzing trends and predicting outcomes, and working with clients to understand how these insights can be used to improve program efficiency. Data Analysts are able to work both as part of a team and independently, completing projects in a fast-paced environment, error-free, and on short deadlines. You will receive strong mentorship from senior members of the BlueLabs Data Science and Engagement teams, and also be given a chance to complete projects independently. BlueLabs Analysts have the opportunity to develop into the Data Science or Engagement tracks within BlueLabs.\\nWhat you'll do:\\n\\nAnalyzes data, as well as contributes to the design, implementation, and delivery of analytics products and services.\\nBuilds predictive models, tools, and data visualizations.\\nChecks data and modeling results for quality and cleans, transforms, aggregates, and reports on data as needed.\\nStrives to support team excellence by documenting processes and evangelizing new approaches\\n\\n\\nPreferred Experience & Background\\n\\nAn undergraduate degree in a quantitative field or equivalent work experience.\\nConceptual understanding of foundations of statistics and modeling (distributions, parameter estimation, confidence intervals and tests, etc.).\\nProficient understanding of a statistical programming language such as R, Python, or Julia.\\nThe ability to effectively communicate technical concepts to a non-technical audience, both in writing and verbally\\nThe ability to manipulate data with SQL.\\nExperience building predictive models using regression and machine learning techniques.\\nKnowledge of experimental design and causal inference experience with GIS.\\nExperience creating informative and engaging data visualizations using industry leading tools.\\nThe ability to create user interfaces for new products using frameworks such as Shiny or Django.\\n\\n\\nThe salary for this position is $67,000/year. We are always looking for great team members to join BlueLabs, but are not actively filling a spot at this time.\\nAt BlueLabs, we celebrate, support and thrive on differences. Not only do they benefit our services, products, and community, but most importantly, they are to the benefit of our team. Qualified people of all races, ethnicities, ages, sex, genders, sexual orientations, national origins, gender identities, marital status, religions, veterans statuses, and disabilities are strongly encouraged to apply. As an equal opportunity workplace and an affirmative action employer, BlueLabs is committed to creating an inclusive environment for all employees.\")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_listing_data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data from next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        next_page_url = indeed_url + soup.find('a', {'aria-label':'Next'}).get('href')\n",
    "    except AttributeError:\n",
    "        break\n",
    "        \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    job_cards = soup.find_all('div','jobsearch-SerpJobCard')\n",
    "    \n",
    "    for card in job_cards:\n",
    "        job_listing_data.append(get_data_from_card(card))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Data analyst',\n",
       " 'Data Analyst',\n",
       " 'Junction Point',\n",
       " 'Remote',\n",
       " 'Remote',\n",
       " '$47,835 - $113,481 a year',\n",
       " '',\n",
       " 'Active 2 days ago',\n",
       " '03/29/21',\n",
       " 'https://www.indeed.com/company/Junction-Point/jobs/Data-Analyst-41717d8e908c8fad?fccid=c722a76f876ecd58&vjs=3',\n",
       " \"I am looking for experienced data analyst to manage my newly established company in Chicago. I need someone with data management skill as my company will be about managing the taxation file of every residence on the Illinois area. Its a work from home job. I will be working closely with you and also will be providing the training. For skill requirement I am looking for 2 years in Excel and SQL as it's needed for my work.Job Types: Full-time, Part-time, ContractPay: $47,835.00 - $113,481.00 per yearSchedule:8 hour shiftEducation:Bachelor's (Preferred)Experience:SQL: 1 year (Preferred)Microsoft Excel: 1 year (Preferred)Contract Length:1 yearContract Renewal:LikelyFull Time Opportunity:NoWork Location:Fully RemoteCOVID-19 Precaution(s):Remote interview process\")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_listing_data)\n",
    "job_listing_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from time import sleep\n",
    "from datetime import date\n",
    "import pickle\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "\n",
    "indeed_url = 'https://www.indeed.com'\n",
    "job_search_url = 'https://www.indeed.com/jobs?q={}&l={}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(title,location):\n",
    "    title = title.replace(' ', '+')\n",
    "    location = location.replace(' ', '+')\n",
    "    url = job_search_url.format(title,location)\n",
    "    return url\n",
    "\n",
    "def get_job_desc(job_url):\n",
    "    time.sleep(20)\n",
    "    job_details = requests.get(job_url)\n",
    "    detail_soup = BeautifulSoup(job_details.text, 'html.parser')\n",
    "\n",
    "    job_desc = detail_soup.find('div','jobsearch-jobDescriptionText').text.strip()\n",
    "    return job_desc\n",
    "\n",
    "\n",
    "def get_data_from_card(card,job_search_id):\n",
    "    title = card.h2.a.get('title') #get method is prefered as it handles key not found error\n",
    "    try:\n",
    "        company_name = card.find('span', 'company').text.strip()\n",
    "    except AttributeError:\n",
    "        company_name=''\n",
    "    location = card.find('div','recJobLoc').get('data-rc-loc')\n",
    "   \n",
    "    if(',' in location):\n",
    "        state = location.split(',')[1].strip()\n",
    "    else:\n",
    "        state = location\n",
    "    \n",
    "    try:\n",
    "        salary = card.find('span','salaryText').text.strip()\n",
    "    except AttributeError:\n",
    "        salary = ''\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        job_rating = card.find('span','ratingsContent').text.strip()\n",
    "    except AttributeError:\n",
    "        job_rating = ''\n",
    "        \n",
    "    try:\n",
    "        posted_date = card.find('span','date').text\n",
    "    except AttributeError:\n",
    "        posted_date = ''\n",
    "        \n",
    "    today = date.today().strftime('%m/%d/%y')\n",
    "    \n",
    "    job_desc_url = indeed_url + card.h2.a.get('href')\n",
    "    job_desc = get_job_desc(job_desc_url)\n",
    "    \n",
    "    card_data = (job_search_id,title, company_name, location, state, salary, job_rating, posted_date, today,job_desc_url,job_desc)\n",
    "    return card_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(title,location):\n",
    "    \n",
    "    \n",
    "    url = get_url(title,location)\n",
    "    \n",
    "    while True:\n",
    "        time.sleep(100)\n",
    "        response = requests.get(url)\n",
    "        print(response.status_code)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            job_cards = soup.find_all('div', 'jobsearch-SerpJobCard')\n",
    "            for card in job_cards:\n",
    "                job_listing = get_data_from_card(card,title)\n",
    "                job_listing_data.append(job_listing)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            url = indeed_url + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "        except AttributeError:\n",
    "            break\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the main method for all the job title and all the locations in a list\n",
    "# save the data in a pickle file\n",
    "\n",
    "titles = ['Data Analyst','Data Scientist', 'Data Engineer','Business Analyst','Product Analyst', 'Business Intelligence Engineer','Software Engineer', 'Devops Engineer','Project Manager','Product Manager']\n",
    "US_states = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District of Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Washington\",'Washington DC' \"Wisconsin\", \"West Virginia\", \"Wyoming\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title = \"Data Analyst\"\n",
    "location = \"United States\"\n",
    "\n",
    "job_listing_data = []\n",
    "try:\n",
    "    main(title,location)\n",
    "except Exception as e: \n",
    "        print(title,'United States')\n",
    "        print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n",
    "        print(e) \n",
    "        print(\"***********************************************\")\n",
    "print(title, len(job_listing_data))\n",
    "createPickleFile(title)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the list in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPickleFile(filename):\n",
    "    \n",
    "    file_name = filename + 'Indeed_jobs_listing.pkl'\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(job_listing_data, f)\n",
    "    print(\"pickle created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'rb') as f:\n",
    "    data = pickle.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
